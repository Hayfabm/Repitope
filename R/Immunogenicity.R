#' Immunogenicity prediction.
#'
#' \code{Immunogenicity} is a wrapper function for training and evaluating a stacked classifier.\cr
#' \code{Immunogenicity_Benchmark} is a wrapper function for benchmarking classifiers implemented in the \code{mlr} package.\cr
#'
#' @param preprocessedDFList An output generated by \code{Features_Preprocess}, \code{Features_CorFilter}, or \code{Features_FeatureSelect}.
#' @param featureSet A set of features to be used for model training. If "all", all features in the training dataframe except "DataType", "Immunogenicity", "Peptide", and "Cluster" will be used.
#' @param learnerSet (Optional) A set of learner strings to be used for model benchmarking. Set \code{NULL} to ignore.
#' @param omitLearnerSet (Optional) A set of learner strings to be omitted from model benchmarking. Set \code{NULL} to ignore.
#' @param destDir A directory for loading & exporting data.
#' @param outputHeader A file/folder name header.
#' @param maxJavaMemory The upper limit of memory for Java virtual machine.
#' @param coreN The number of cores to be used for parallelization. Set \code{NULL} to skip parallelization.
#' @importFrom dplyr %>%
#' @importFrom dplyr select
#' @importFrom dplyr filter
#' @importFrom dplyr slice
#' @importFrom dplyr mutate
#' @importFrom dplyr bind_cols
#' @importFrom dplyr bind_rows
#' @importFrom dplyr left_join
#' @importFrom dplyr group_by
#' @importFrom dplyr summarise
#' @importFrom readr read_csv
#' @importFrom readr write_csv
#' @importFrom stringr str_split
#' @importFrom stringr fixed
#' @importFrom pacman p_install
#' @importFrom pacman p_unload
#' @importFrom DescTools Sort
#' @importFrom data.table as.data.table
#' @importFrom data.table rbindlist
#' @importFrom parallel detectCores
#' @importFrom parallelMap parallelStartSocket
#' @importFrom parallelMap parallelStop
#' @importFrom pbapply pblapply
#' @import mlr
#' @export
#' @rdname Immunogenicity
#' @name Immunogenicity
Immunogenicity <- function(
  preprocessedDFList, featureSet="all",
  destDir="./Immunogenicity/", outputHeader="Output",
  maxJavaMemory="6G", coreN=parallel::detectCores()
){
  # Working environment
  dir.create(destDir, showWarnings=F, recursive=T)
  options(java.parameters=gsub("-Xmx-Xmx", "-Xmx", paste0("-Xmx", maxJavaMemory))) ## Before calling library(mlr)!

  # Input check
  if(any(class(preprocessedDFList[[1]])=="data.frame")) preprocessedDFList <- lapply(preprocessedDFList, function(d){list("dt"=d)})

  # Batch machine learning
  leng <- length(preprocessedDFList)
  predDFList <- as.list(rep(NA, leng))
  measureDFList <- as.list(rep(NA, leng))
  cat("Number of datasets = ", leng, "\n", sep="")
  stackML <- function(preprocessedDFList, i){
    library(mlr)
    library(parallelMap)

    ## Parameter check
    param <- names(preprocessedDFList)[i]
    s <- try(as.integer(rev(unlist(stringr::str_split(param, stringr::fixed("."))))[1]), silent=T)
    if(any(class(s)=="try-error")) s <- 123456789  ## ad hoc seed
    set.seed(s)
    cat(i, "/", leng, "| Parameter set: ", param, "\n", sep="")

    ## Destination directory
    modDir <- paste0(destDir, "/", outputHeader, "_", param)
    dir.create(modDir, showWarnings=F, recursive=T)

    ## Input data check
    dt <- preprocessedDFList[[i]]$"dt"
    if(is.null(dt$"DataType")){
      message("The input datatable is not valid! No 'DataType' column is detected.")
      return(NULL)
    }
    dt_train <- dt %>%
      dplyr::filter(DataType=="Train") %>%
      dplyr::select(-DataType, -Peptide, -Cluster) %>%
      as.data.frame()
    dt_test <- dt %>%
      dplyr::filter(DataType=="Test") %>%
      dplyr::select(-DataType, -Peptide, -Cluster) %>%
      as.data.frame()

    ## Model training
    if(!is.null(coreN)) parallelMap::parallelStartSocket(cpus=coreN)
    skipQ <- file.exists(file.path(modDir, "Predictions.csv"))&file.exists(file.path(modDir, "PerformanceMeasures.csv"))
    if(skipQ==F){
      ### Learners
      lrns <- list(
        mlr::makeLearner("classif.extraTrees", predict.type="prob"),
        mlr::makeLearner("classif.randomForestSRC", predict.type="prob"),
        mlr::makeLearner("classif.svm", predict.type="prob", par.vals=list(cost=0.0133, gamma=0.02)),
        mlr::makeLearner("classif.xgboost", predict.type="prob", par.vals=list(booster="gbtree", eta=0.1))
      )

      ### Features
      if(identical(featureSet, "all")) featureSet <- colnames(dt_train)
      featureSet <- setdiff(featureSet, c("DataType", "Peptide", "Cluster"))
      dt_mod <- dplyr::select(dt_train, featureSet)

      ### Task
      tsk <- mlr::makeClassifTask(data=as.data.frame(dt_mod), target="Immunogenicity")

      ### Class weights [Stacked classifier does not support this!]
      #target <- mlr::getTaskTargets(tsk)
      #tab <- as.numeric(table(target))
      #w <- 1/tab[target]
      #tsk <- mlr::makeClassifTask(data=as.data.frame(data), target="Immunogenicity", weights=w)

      ### Model training
      cat("Constructing stacked model...\n")
      stk.lrn <- mlr::makeStackedLearner(base.learners=lrns, super.learner="classif.extraTrees", predict.type="prob", method="stack.cv")
      stck <- mlr::train(learner=stk.lrn, task=tsk)
      saveRDS(stck, file.path(modDir, "StackedModel.rds"))

      ### Prediction
      cat("Immunogenicity predictions...\n", sep="")
      tsk_train <- mlr::makeClassifTask(data=dt_train, target="Immunogenicity")
      tsk_test <- mlr::makeClassifTask(data=dt_test, target="Immunogenicity")
      pred_train <- predict(stck, tsk_train)
      pred_test <- predict(stck, tsk_test)
      predDFList[[i]] <- data.table::rbindlist(list(
        data.frame("Param"=param, "DataType"="Train", as.data.frame(pred_train)),
        data.frame("Param"=param, "DataType"="Test", as.data.frame(pred_test))
      ))
      measureDFList[[i]] <- data.table::rbindlist(list(
        as.data.frame(c(list("Param"=param, "DataType"="Train"), as.list(mlr::performance(pred_train, measures=list(mlr::timeboth, mlr::auc, mlr::kappa), task=tsk_train, model=stck)), mlr::calculateROCMeasures(pred_train)$"measures")),
        as.data.frame(c(list("Param"=param, "DataType"="Test"), as.list(mlr::performance(pred_test, measures=list(mlr::timeboth, mlr::auc, mlr::kappa), task=tsk_train, model=stck)), mlr::calculateROCMeasures(pred_test)$"measures"))
      ))
      print(measureDFList[[i]])
      readr::write_csv(predDFList[[i]], file.path(modDir, "Predictions.csv"))
      readr::write_csv(measureDFList[[i]], file.path(modDir, "PerformanceMeasures.csv"))
    }else{
      cat("Model training was skipped.\n")
      predDFList[[i]] <- readr::read_csv(file.path(modDir, "Predictions.csv"))
      measureDFList[[i]] <- readr::read_csv(file.path(modDir, "PerformanceMeasures.csv"))
    }

    ## Closing
    if(!is.null(coreN)) parallelMap::parallelStop()
    try(pacman::p_unload("all"), silent=T)
    rm(list=setdiff(ls(), c("predDFList", "measureDFList")))
    gc();gc()
  }
  for(i in 1:leng){ try(stackML(preprocessedDFList, i)) }

  # Outputs
  predDF <- data.table::rbindlist(predDFList)
  measureDF <- data.table::rbindlist(measureDFList)
  readr::write_csv(predDF, file.path(destDir, paste0(outputHeader, "_Predictions.csv")))
  readr::write_csv(measureDF, file.path(destDir, paste0(outputHeader, "_PerformanceMeasures.csv")))
  rm(list=setdiff(ls(), c("predDF", "measureDF")))
  gc();gc()
  return(list("predDF"=predDF, "measureDF"=measureDF))
}

#' @export
#' @rdname Immunogenicity
#' @name Immunogenicity_Benchmark
Immunogenicity_Benchmark <- function(
  preprocessedDFList, learnerSet=NULL, omitLearnerSet=NULL,
  destDir="./Benchmark/", maxJavaMemory="6G", coreN=parallel::detectCores()
){
  # Working environment
  dir.create(destDir, showWarnings=F, recursive=T)
  options(java.parameters=gsub("-Xmx-Xmx", "-Xmx", paste0("-Xmx", maxJavaMemory))) ## Before calling library(mlr)!

  # Input check
  if(any(class(preprocessedDFList[[1]])=="data.frame")) preprocessedDFList <- lapply(preprocessedDFList, function(d){list("dt"=d)})

  # Tasks
  preprocessedDFList_to_taskList <- function(preprocessedDFList, maxRowN=10000){
    pbapply::pblapply(1:length(preprocessedDFList), function(i){
      param <- names(preprocessedDFList)[i]
      s <- try(as.integer(rev(unlist(stringr::str_split(param, stringr::fixed("."))))[1]), silent=T)
      if(any(class(s)=="try-error")) s <- 123456789  ## ad hoc seed
      set.seed(s)
      dt <- preprocessedDFList[[i]][["dt"]] %>% dplyr::select(-DataType, -Peptide, -Cluster)
      if(nrow(dt)>maxRowN) dt <- dplyr::slice(dt, sample(1:nrow(dt), maxRowN))
      tsk <- mlr::makeClassifTask(id=paste0("Benchmark_", param), data=as.data.frame(dt), target="Immunogenicity")
      #target <- mlr::getTaskTargets(tsk)
      #tab <- as.numeric(table(target))
      #w <- 1/tab[target]
      #tsk <- mlr::makeClassifTask(id=paste0("Benchmark_", param), data=as.data.frame(dt), target="Immunogenicity", weights=w)
      return(tsk)
    })
  }
  message("Converting preprocessed dataframes into a list of tasks...")
  taskSet <- preprocessedDFList_to_taskList(preprocessedDFList, maxRowN=10000)
  gc();gc()

  # Learners
  message("Preparing required packages...")
  lrns.df <- suppressWarnings(mlr::listLearners("classif", properties=c("twoclass", "prob")))
  if(is.null(learnerSet)) learnerSet <- lrns.df$"class"
  if(is.null(omitLearnerSet)) omitLearnerSet <- c()
  omitLearnerSet <- c(omitLearnerSet, gsub(".rds", "", gsub("BenchmarkResult_", "", basename(list.files(pattern="^BenchmarkResult.+rds$", path=destDir, full.names=T))), fixed=T))
  learnerSet <- setdiff(learnerSet, omitLearnerSet)
  lrns.df <- dplyr::filter(lrns.df, class %in% learnerSet)
  lrns.pkg <- lrns.df$package
  lrns.pkg <- setdiff(lrns.pkg, as.character(as.data.frame(installed.packages())$"Package"))
  if(length(lrns.pkg)>=1) pacman::p_install(lrns.pkg, character.only=T)
  gc();gc()

  # Benchmarking
  message("Starting benchmark experiments...")
  bm_wrapper <- function(learnerString, tasks){
    library(mlr)
    library(parallelMap)
    set.seed(12345)
    message(learnerString)
    msrs <- list(
      mlr::timeboth, mlr::setAggregation(mlr::timeboth, mlr::train.mean),
      mlr::auc, mlr::setAggregation(mlr::auc, mlr::train.mean),
      mlr::logloss, mlr::setAggregation(mlr::logloss, mlr::train.mean),
      mlr::acc, mlr::setAggregation(mlr::acc, mlr::train.mean),
      mlr::kappa, mlr::setAggregation(mlr::kappa, mlr::train.mean),
      mlr::ber, mlr::setAggregation(mlr::ber, mlr::train.mean)
    )
    if(!is.null(coreN)){
      parallelMap::parallelStartSocket(cpus=coreN)
      bmr <- mlr::benchmark(
        learners=mlr::makeLearner(learnerString, predict.type="prob"),
        tasks=tasks,
        measures=msrs,
        resamplings=mlr::makeResampleDesc(method="CV", iters=3, predict="both"),
        show.info=F
      )
      parallelMap::parallelStop()
    }else{
      bmr <- mlr::benchmark(
        learners=mlr::makeLearner(learnerString, predict.type="prob"),
        tasks=tasks,
        measures=msrs,
        resamplings=mlr::makeResampleDesc(method="CV", iters=3, predict="both"),
        show.info=F
      )
    }
    print(bmr)
    saveRDS(bmr, file.path(destDir, paste0("BenchmarkResult_", learnerString, ".rds")))
    bmr.df <- as.data.frame(bmr)
    readr::write_csv(bmr.df, file.path(destDir, paste0("BenchmarkResult_", learnerString, ".csv")))
    try(pacman::p_unload("all"), silent=T)
    rm(list=ls())
    gc();gc()
  }
  for(l in learnerSet){ try(bm_wrapper(l, taskSet)) }
  message("Integrating benchmark results...\n")
  bmfiles <- list.files(pattern="^BenchmarkResult.+csv$", path=destDir, full.names=T)
  bmfiles <- setdiff(bmfiles, file.path(destDir, "BenchmarkResult_Combined.csv"))
  bmr <- dplyr::bind_rows(lapply(bmfiles, readr::read_csv))
  bmr.ord <- bmr %>%
    dplyr::group_by(learner.id) %>% dplyr::summarise(auc=mean(auc)) %>%
    DescTools::Sort(ord="auc", decreasing=F) %>%
    dplyr::select(-auc)
  bmr <- dplyr::left_join(bmr.ord, bmr)
  readr::write_csv(bmr, file.path(destDir, "BenchmarkResult_Combined.csv"))
  return(bmr)
}

