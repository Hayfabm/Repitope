#' Immunogenicity prediction.
#'
#' \code{Immunogenicity} is a wrapper function for training and evaluating an extraTrees classifier.\cr
#' \code{Immunogenicity_Benchmark} is a wrapper function for benchmarking classifiers implemented in the \code{mlr} package.\cr
#'
#' @param preprocessedDFList An output generated by \code{Features_Preprocess}, \code{Features_CorFilter}, or \code{Features_FeatureSelect}.
#' @param featureSet A set of features to be used for model training. If "all", all features in the training dataframe except "DataType", "Immunogenicity", "Peptide", and "Cluster" will be used.
#' @param learnerSet (Optional) A set of learner strings to be used for model benchmarking. Set \code{NULL} to ignore.
#' @param omitLearnerSet (Optional) A set of learner strings to be omitted from model benchmarking. Set \code{NULL} to ignore.
#' @param destDir A directory for loading & exporting data.
#' @param outputHeader A file/folder name header.
#' @param maxJavaMemory The upper limit of memory for Java virtual machine.
#' @param coreN The number of cores to be used for parallelization. Set \code{NULL} to skip parallelization.
#' @importFrom dplyr %>%
#' @importFrom dplyr select
#' @importFrom dplyr filter
#' @importFrom dplyr slice
#' @importFrom dplyr mutate
#' @importFrom dplyr bind_cols
#' @importFrom dplyr bind_rows
#' @importFrom dplyr left_join
#' @importFrom dplyr group_by
#' @importFrom dplyr summarise
#' @importFrom readr read_csv
#' @importFrom readr write_csv
#' @importFrom stringr str_split
#' @importFrom stringr fixed
#' @importFrom pacman p_install
#' @importFrom pacman p_unload
#' @importFrom DescTools Sort
#' @importFrom data.table as.data.table
#' @importFrom data.table rbindlist
#' @importFrom parallel detectCores
#' @importFrom parallelMap parallelStartSocket
#' @importFrom parallelMap parallelStop
#' @importFrom pbapply pblapply
#' @import mlr
#' @export
#' @rdname Immunogenicity
#' @name Immunogenicity
Immunogenicity <- function(
  preprocessedDFList=NULL, featureSet="all",
  destDir="./Immunogenicity/", outputHeader="Output",
  maxJavaMemory="6G", coreN=parallel::detectCores()
){
  # Internally used functions
  machine_learning <- function(preprocessedDFList, i){
    ## Parameter check
    param <- names(preprocessedDFList)[i]
    s <- try(as.integer(rev(unlist(stringr::str_split(param, stringr::fixed("."))))[1]), silent=T)
    if(any(class(s)=="try-error")) s <- 123456789  ## ad hoc seed
    set.seed(s)
    cat(i, "/", leng, "| Parameter set: ", param, "\n", sep="")

    ## Destination directory check
    modDir <- paste0(destDir, "/", outputHeader, "_", param)
    dir.create(modDir, showWarnings=F, recursive=T)
    skipQ <- file.exists(file.path(modDir, "Predictions.csv")) & file.exists(file.path(modDir, "PerformanceMeasures.csv"))
    if(skipQ){
      cat("Machine learning was skipped.\n")
      return(NULL)
    }

    ## Input data check
    dt <- preprocessedDFList[[i]]$"dt"
    if(is.null(dt$"DataType")){
      message("The input datatable is not valid! 'DataType' column is required.")
      return(NULL)
    }
    if(identical(featureSet, "all")) featureSet <- colnames(dt)
    featureSet <- unique(c("Immunogenicity", setdiff(featureSet, c("DataType", "Peptide", "Cluster"))))
    dt_train <- dt %>%
      dplyr::filter(DataType=="Train") %>%
      dplyr::select(featureSet) %>%
      as.data.frame()
    dt_test <- dt %>%
      dplyr::filter(DataType=="Test") %>%
      dplyr::select(featureSet) %>%
      as.data.frame()

    ## Parallelization
    library(mlr)
    library(parallelMap)
    if(!is.null(coreN)) parallelMap::parallelStartSocket(cpus=coreN)

    ## Learner
    lrn <- mlr::makeLearner("classif.extraTrees", predict.type="prob", mtry=35, numRandomCuts=2)  ## optimized from preliminary experiments

    ## Task
    tsk <- mlr::makeClassifTask(data=as.data.frame(dt_train), target="Immunogenicity")

    ## Class weights [Stacked classifier does not support this!]
    target <- mlr::getTaskTargets(tsk)
    tab <- as.numeric(table(target))
    w <- 1/tab[target]
    tsk <- mlr::makeClassifTask(data=as.data.frame(dt_train), target="Immunogenicity", weights=w)

    ## Model training
    cat("Constructing model...\n")
    mod <- mlr::train(learner=lrn, task=tsk)
    saveRDS(mod, file.path(modDir, "Model.rds"))

    ## Prediction
    cat("Predicting immunogenicity...\n", sep="")
    tsk_train <- mlr::makeClassifTask(data=dt_train, target="Immunogenicity")
    tsk_test <- mlr::makeClassifTask(data=dt_test, target="Immunogenicity")
    pred_train <- predict(mod, task=tsk_train)
    pred_test <- predict(mod, task=tsk_test)
    predDF <- data.table::rbindlist(list(
      data.frame("Param"=param, "DataType"="Train", as.data.frame(pred_train)),
      data.frame("Param"=param, "DataType"="Test", as.data.frame(pred_test))
    ))
    measureDF <- data.table::rbindlist(list(
      as.data.frame(c(list("Param"=param, "DataType"="Train"), as.list(mlr::performance(pred_train, measures=list(mlr::timeboth, mlr::auc, mlr::kappa), task=tsk_train, model=mod)), mlr::calculateROCMeasures(pred_train)$"measures")),
      as.data.frame(c(list("Param"=param, "DataType"="Test"), as.list(mlr::performance(pred_test, measures=list(mlr::timeboth, mlr::auc, mlr::kappa), task=tsk_train, model=mod)), mlr::calculateROCMeasures(pred_test)$"measures"))
    ))
    print(measureDF)
    readr::write_csv(predDF, file.path(modDir, "Predictions.csv"))
    readr::write_csv(measureDF, file.path(modDir, "PerformanceMeasures.csv"))

    ## Closing
    if(!is.null(coreN)) parallelMap::parallelStop()
    try(pacman::p_unload("all"), silent=T)
    gc();gc()
    return(NULL)
  }
  concatenate_results <- function(destDir){
    cat("Concatenating results...\n")
    predDFList <- pbapply::pblapply(list.files(pattern="^Predictions.csv$", path=destDir, recursive=T, full.names=T), function(f){suppressMessages(readr::read_csv(f, col_types='ccicddc_'))})
    measureDFList <- pbapply::pblapply(list.files(pattern="^PerformanceMeasures.csv$", path=destDir, recursive=T, full.names=T), function(f){suppressMessages(readr::read_csv(f))})
    predDF <- data.table::rbindlist(predDFList)
    measureDF <- data.table::rbindlist(measureDFList)
    readr::write_csv(predDF, file.path(destDir, paste0(outputHeader, "_Predictions.csv")))
    readr::write_csv(measureDF, file.path(destDir, paste0(outputHeader, "_PerformanceMeasures.csv")))
    return(list("predDF"=predDF, "measureDF"=measureDF))
  }

  # Working environment
  dir.create(destDir, showWarnings=F, recursive=T)
  options(java.parameters=gsub("-Xmx-Xmx", "-Xmx", paste0("-Xmx", maxJavaMemory))) ## Before calling library(mlr)!

  # Just concatenating previous CSV files
  if(is.null(preprocessedDFList)){
    res <- concatenate_results(destDir)
    rm(list=setdiff(ls(), c("res")))
    gc();gc()
    return(res)
  }

  # Input formatting
  if(any(sapply(preprocessedDFList, is.data.frame))){
    preprocessedDFList <- lapply(preprocessedDFList, function(d){list("dt"=d)})
  }

  # Batch machine learning
  leng <- length(preprocessedDFList)
  cat("Number of datasets = ", leng, "\n", sep="")
  for(i in 1:leng){
    try(machine_learning(preprocessedDFList, i))
  }

  # Outputs
  res <- concatenate_results(destDir)
  rm(list=setdiff(ls(), c("res")))
  gc();gc()
  return(res)
}

#' @export
#' @rdname Immunogenicity
#' @name Immunogenicity_Benchmark
Immunogenicity_Benchmark <- function(
  preprocessedDFList, learnerSet=NULL, omitLearnerSet=NULL,
  destDir="./Benchmark/", maxJavaMemory="6G", coreN=parallel::detectCores()
){
  # Working environment
  dir.create(destDir, showWarnings=F, recursive=T)
  options(java.parameters=gsub("-Xmx-Xmx", "-Xmx", paste0("-Xmx", maxJavaMemory))) ## Before calling library(mlr)!

  # Input check
  if(any(class(preprocessedDFList[[1]])=="data.frame")) preprocessedDFList <- lapply(preprocessedDFList, function(d){list("dt"=d)})

  # Tasks
  preprocessedDFList_to_taskList <- function(preprocessedDFList, maxRowN=10000){
    pbapply::pblapply(1:length(preprocessedDFList), function(i){
      param <- names(preprocessedDFList)[i]
      s <- try(as.integer(rev(unlist(stringr::str_split(param, stringr::fixed("."))))[1]), silent=T)
      if(any(class(s)=="try-error")) s <- 123456789  ## ad hoc seed
      set.seed(s)
      dt <- preprocessedDFList[[i]][["dt"]] %>% dplyr::select(-DataType, -Peptide, -Cluster)
      if(nrow(dt)>maxRowN) dt <- dplyr::slice(dt, sample(1:nrow(dt), maxRowN))
      tsk <- mlr::makeClassifTask(id=paste0("Benchmark_", param), data=as.data.frame(dt), target="Immunogenicity")
      #target <- mlr::getTaskTargets(tsk)
      #tab <- as.numeric(table(target))
      #w <- 1/tab[target]
      #tsk <- mlr::makeClassifTask(id=paste0("Benchmark_", param), data=as.data.frame(dt), target="Immunogenicity", weights=w)
      return(tsk)
    })
  }
  message("Converting preprocessed dataframes into a list of tasks...")
  taskSet <- preprocessedDFList_to_taskList(preprocessedDFList, maxRowN=10000)
  gc();gc()

  # Learners
  message("Preparing required packages...")
  lrns.df <- suppressWarnings(mlr::listLearners("classif", properties=c("twoclass", "prob")))
  if(is.null(learnerSet)) learnerSet <- lrns.df$"class"
  if(is.null(omitLearnerSet)) omitLearnerSet <- c()
  omitLearnerSet <- c(omitLearnerSet, gsub(".rds", "", gsub("BenchmarkResult_", "", basename(list.files(pattern="^BenchmarkResult.+rds$", path=destDir, full.names=T))), fixed=T))
  learnerSet <- setdiff(learnerSet, omitLearnerSet)
  lrns.df <- dplyr::filter(lrns.df, class %in% learnerSet)
  lrns.pkg <- lrns.df$package
  lrns.pkg <- setdiff(lrns.pkg, as.character(as.data.frame(installed.packages())$"Package"))
  if(length(lrns.pkg)>=1) pacman::p_install(lrns.pkg, character.only=T)
  gc();gc()

  # Benchmarking
  message("Starting benchmark experiments...")
  bm_wrapper <- function(learnerString, tasks){
    library(mlr)
    library(parallelMap)
    set.seed(12345)
    message(learnerString)
    msrs <- list(
      mlr::timeboth, mlr::setAggregation(mlr::timeboth, mlr::train.mean),
      mlr::auc, mlr::setAggregation(mlr::auc, mlr::train.mean),
      mlr::logloss, mlr::setAggregation(mlr::logloss, mlr::train.mean),
      mlr::acc, mlr::setAggregation(mlr::acc, mlr::train.mean),
      mlr::kappa, mlr::setAggregation(mlr::kappa, mlr::train.mean),
      mlr::ber, mlr::setAggregation(mlr::ber, mlr::train.mean)
    )
    if(!is.null(coreN)){
      parallelMap::parallelStartSocket(cpus=coreN)
      bmr <- mlr::benchmark(
        learners=mlr::makeLearner(learnerString, predict.type="prob"),
        tasks=tasks,
        measures=msrs,
        resamplings=mlr::makeResampleDesc(method="CV", iters=3, predict="both"),
        show.info=T
      )
      parallelMap::parallelStop()
    }else{
      bmr <- mlr::benchmark(
        learners=mlr::makeLearner(learnerString, predict.type="prob"),
        tasks=tasks,
        measures=msrs,
        resamplings=mlr::makeResampleDesc(method="CV", iters=3, predict="both"),
        show.info=T
      )
    }
    print(bmr)
    saveRDS(bmr, file.path(destDir, paste0("BenchmarkResult_", learnerString, ".rds")))
    bmr.df <- as.data.frame(bmr)
    readr::write_csv(bmr.df, file.path(destDir, paste0("BenchmarkResult_", learnerString, ".csv")))
    try(pacman::p_unload("all"), silent=T)
    rm(list=ls())
    gc();gc()
  }
  for(l in learnerSet){ try(bm_wrapper(l, taskSet)) }
  message("Integrating benchmark results...\n")
  bmfiles <- list.files(pattern="^BenchmarkResult.+csv$", path=destDir, full.names=T)
  bmfiles <- setdiff(bmfiles, file.path(destDir, "BenchmarkResult_Combined.csv"))
  bmr <- dplyr::bind_rows(lapply(bmfiles, readr::read_csv))
  bmr.ord <- bmr %>%
    dplyr::group_by(learner.id) %>% dplyr::summarise(auc=mean(auc)) %>%
    DescTools::Sort(ord="auc", decreasing=F) %>%
    dplyr::select(-auc)
  bmr <- dplyr::left_join(bmr.ord, bmr)
  readr::write_csv(bmr, file.path(destDir, "BenchmarkResult_Combined.csv"))
  return(bmr)
}

