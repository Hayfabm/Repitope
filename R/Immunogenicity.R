#' Immunogenicity prediction.
#'
#' \code{Immunogenicity} is a wrapper function for training and evaluating a classifier. The optimized algorithm is used by default.\cr
#'
#' @param preprocessedDFList An output generated by \code{Features_Preprocess}, \code{Features_CorFilter}, or \code{Features_FeatureSelect}.
#' @param featureSet A set of features to be used for model training. If "all", all features in the training dataframe except "DataType", "Immunogenicity", "Peptide", and "Cluster" will be used.
#' @param destDir A directory for loading & exporting data.
#' @param outputHeader A file/folder name header for the outputs to be saved.
#' @param coreN The number of cores to be used for parallelization. Set \code{NULL} to skip parallelization.
#' @importFrom dplyr %>%
#' @importFrom dplyr select
#' @importFrom dplyr filter
#' @importFrom dplyr mutate
#' @importFrom readr read_csv
#' @importFrom readr write_csv
#' @importFrom stringr str_split
#' @importFrom stringr fixed
#' @importFrom DescTools Sort
#' @importFrom data.table as.data.table
#' @importFrom data.table rbindlist
#' @importFrom parallel detectCores
#' @importFrom pbapply pblapply
#' @importFrom extraTrees extraTrees
#' @importFrom caret confusionMatrix
#' @importFrom pROC roc
#' @importFrom pROC auc
#' @export
#' @rdname Immunogenicity
#' @name Immunogenicity
Immunogenicity <- function(
  preprocessedDFList=NULL, featureSet="all",
  destDir="./Immunogenicity/", outputHeader="Output",
  coreN=parallel::detectCores()
){
  # Working environment
  dir.create(destDir, showWarnings=F, recursive=T)

  # Internally used functions
  machine_learning <- function(preprocessedDFList, i){
    ## Parameter check
    param <- names(preprocessedDFList)[i]
    s <- try(as.integer(rev(unlist(stringr::str_split(param, stringr::fixed("."))))[1]), silent=T)
    if(any(class(s)=="try-error")) s <- 123456789  ## ad hoc seed
    set.seed(s)
    cat("Parameter set ", i, ": ", param, "\n", sep="")

    ## Skipping
    out <- paste0(destDir, "/", outputHeader, "_", param, "_")
    skipQ <- file.exists(paste0(out, "Predictions.csv")) & file.exists(paste0(out, "PerformanceMeasures.csv"))
    if(skipQ){
      cat("Machine learning was skipped.\n")
      return(NULL)
    }

    ## Input data check
    dt <- preprocessedDFList[[i]]$"dt"
    if(is.null(dt$"DataType")){
      message("The input datatable is not valid! 'DataType' column is required.")
      return(NULL)
    }
    if(identical(featureSet, "all")) featureSet <- colnames(dt)
    featureSet <- unique(c("Immunogenicity", setdiff(featureSet, c("DataType", "Peptide", "Cluster"))))
    dt_train <- dt %>%
      dplyr::filter(DataType=="Train") %>%
      dplyr::select(featureSet) %>%
      as.data.frame()
    dt_test <- dt %>%
      dplyr::filter(DataType=="Test") %>%
      dplyr::select(featureSet) %>%
      as.data.frame()

    ## Model training
    cat("Constructing model...\n")
    extraTrees_train_wrapper <- function(orig, featSet=featureSet){
      trgt <- orig$"Immunogenicity"
      tab <- as.numeric(table(trgt))
      w <- 1/tab[trgt]
      dat <- as.matrix(dplyr::select(orig, setdiff(featSet, "Immunogenicity")))
      mod <- extraTrees::extraTrees(
        x=dat, y=orig$"Immunogenicity",
        mtry=35, numRandomCuts=2, weights=w,
        numThreads=ifelse(is.null(coreN), 1, coreN)
      )
      return(mod)
    }
    mod <- extraTrees_train_wrapper(dt_train)

    ## Prediction
    cat("Predicting immunogenicity...\n")
    extraTrees_predict_wrapper <- function(et, newdata, featSet=featureSet){
      dat <- as.matrix(dplyr::select(newdata, setdiff(featSet, "Immunogenicity")))
      pred <- cbind(
        data.frame("PredictedImmunogenicity"=predict(et, dat, probability=F)),
        as.data.frame(predict(et, dat, probability=T))
      )
      return(pred)
    }
    extraTrees_performance_wrapper <- function(pred, orig){
      measure.auc <- as.numeric(pROC::auc(pROC::roc(orig$"Immunogenicity", pred$"Positive")))
      measure.cm <- caret::confusionMatrix(pred$"PredictedImmunogenicity", orig$"Immunogenicity")
      measures <- c(measure.auc, measure.cm$overall[c("Accuracy", "Kappa")], measure.cm$byClass)
      names(measures) <- c("AUC", "Accuracy", "Kappa", "Sensitivity", "Specificity", "PPV", "NPV", "Precision", "Recall", "F1", "Prevalence", "DetectionRate", "DetectionPrevalence", "BalancedAccuracy")
      measures <- as.list(measures)
      return(measures)
    }
    pred_train <- extraTrees_predict_wrapper(mod, newdata=dt_train)
    pred_test <- extraTrees_predict_wrapper(mod, newdata=dt_test)
    measureDF <- data.table::rbindlist(list(
      data.frame("Param"=param, "DataType"="Train", as.data.frame(extraTrees_performance_wrapper(pred_train, dt_train))),
      data.frame("Param"=param, "DataType"="Test", as.data.frame(extraTrees_performance_wrapper(pred_test, dt_test)))
    ))
    predDF <- data.table::rbindlist(list(
      data.frame("Param"=param, "DataType"="Train", as.data.frame(pred_train)),
      data.frame("Param"=param, "DataType"="Test", as.data.frame(pred_test))
    ))
    print(measureDF)
    readr::write_csv(predDF, paste0(out, "Predictions.csv"))
    readr::write_csv(measureDF, paste0(out, "PerformanceMeasures.csv"))

    ## Closing
    rm(list=ls())
    gc();gc()
    return(NULL)
  }
  concatenate_results <- function(destDir){
    cat("Concatenating results...\n")
    predDFList <- pbapply::pblapply(list.files(pattern="Predictions.csv$", path=destDir, full.names=T), function(f){suppressMessages(readr::read_csv(f, col_types='cc_dd'))})
    measureDFList <- pbapply::pblapply(list.files(pattern="PerformanceMeasures.csv$", path=destDir, full.names=T), function(f){suppressMessages(readr::read_csv(f))})
    predDF <- data.table::rbindlist(predDFList)
    measureDF <- data.table::rbindlist(measureDFList)
    readr::write_csv(predDF, file.path(destDir, paste0(outputHeader, "_Predictions_Combined.csv")))
    readr::write_csv(measureDF, file.path(destDir, paste0(outputHeader, "_PerformanceMeasures_Combined.csv")))
    return(list("predDF"=predDF, "measureDF"=measureDF))
  }

  # Main analysis workflow
  if(!is.null(preprocessedDFList)){
    # Input formatting
    if(any(sapply(preprocessedDFList, is.data.frame))){
      preprocessedDFList <- lapply(preprocessedDFList, function(d){list("dt"=d)})
    }
    # Batch machine learning
    leng <- length(preprocessedDFList)
    cat("Number of datasets = ", leng, "\n", sep="")
    res <- lapply(1:leng, function(i){
      try(machine_learning(preprocessedDFList, i), silent=T)
    })
  }

  # Outputs
  res <- concatenate_results(destDir)
  rm(list=setdiff(ls(), c("res")))
  gc();gc()
  return(res)
}

