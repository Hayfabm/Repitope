#' Feature selection based on their importances.
#'
#' @param preprocessedDFList An output generated by \code{Features_Preprocess} or \code{Features_CorFilter}.
#' @param featureN The number of the features that should be retained.
#' @param coreN The number of cores to be used for parallelization. Set \code{NULL} to skip parallelization.
#' @importFrom dplyr %>%
#' @importFrom dplyr select
#' @importFrom dplyr filter
#' @importFrom dplyr slice
#' @importFrom dplyr mutate
#' @importFrom dplyr transmute
#' @importFrom dplyr bind_cols
#' @importFrom dplyr bind_rows
#' @importFrom dplyr left_join
#' @importFrom dplyr group_by
#' @importFrom dplyr summarise
#' @importFrom readr read_csv
#' @importFrom readr write_csv
#' @importFrom stringr str_split
#' @importFrom stringr fixed
#' @importFrom DescTools Sort
#' @importFrom scales rescale
#' @importFrom data.table as.data.table
#' @importFrom parallel detectCores
#' @importFrom parallelMap parallelStartSocket
#' @importFrom parallelMap parallelStop
#' @importFrom pbapply pblapply
#' @import mlr
#' @export
#' @rdname Features_Importance
#' @name Features_Importance
Features_Importance <- function(
  preprocessedDFList, featureN=100, coreN=parallel::detectCores()
){
  # Input check
  if(any(class(preprocessedDFList[[1]])=="data.frame")) preprocessedDFList <- lapply(preprocessedDFList, function(d){list("dt"=d)})

  # Tasks
  preprocessedDFList_to_taskList <- function(preprocessedDFList, maxRowN=Inf){
    pbapply::pblapply(1:length(preprocessedDFList), function(i){
      param <- names(preprocessedDFList)[i]
      s <- try(as.integer(rev(unlist(stringr::str_split(param, stringr::fixed("."))))[1]), silent=T)
      if(any(class(s)=="try-error")) s <- 123456789  ## ad hoc seed
      set.seed(s)
      dt <- preprocessedDFList[[i]][["dt"]] %>% dplyr::select(-DataType, -Peptide, -Cluster)
      if(nrow(dt)>maxRowN) dt <- dplyr::slice(dt, sample(1:nrow(dt), maxRowN))
      tsk <- mlr::makeClassifTask(id=paste0("Benchmark_", param), data=as.data.frame(dt), target="Immunogenicity")
      target <- mlr::getTaskTargets(tsk)
      tab <- as.numeric(table(target))
      w <- 1/tab[target]
      tsk <- mlr::makeClassifTask(data=as.data.frame(dt), target="Immunogenicity", weights=w)
      return(tsk)
    })
  }
  message("Converting preprocessed dataframes into a list of tasks...\n")
  taskSet <- preprocessedDFList_to_taskList(preprocessedDFList, maxRowN=10000)
  gc();gc()

  # Importances
  message("Calculating feature importances...\n")
  time.start <- proc.time()
  conbinedParamSet <- names(preprocessedDFList)
  if(!is.null(coreN)){
    require(parallelMap)
    parallelMap::parallelStartSocket(cpus=coreN)
    featureImportances <- pbapply::pblapply(taskSet, mlr::generateFilterValuesData, method="randomForestSRC.rfsrc")
    parallelMap::parallelStop()
  }else{
    featureImportances <- pbapply::pblapply(taskSet, mlr::generateFilterValuesData, method="randomForestSRC.rfsrc")
  }
  featureImportanceDFList <- lapply(1:length(preprocessedDFList), function(i){
    dt <- data.table::as.data.table(preprocessedDFList[[i]][["dt"]])
    param <- names(preprocessedDFList)[i]
    imp <- featureImportances[[i]][["data"]] %>%
      dplyr::transmute(FeatureID=name, Importance=scales::rescale(randomForestSRC.rfsrc, to=c(0,1)), Parameter=param) %>%
      DescTools::Sort(ord="Importance", decreasing=T)
    if(!is.null(featureN)){
      imp <- dplyr::slice(imp, seq(1, min(nrow(imp), featureN)))
      feat <- as.character(imp[["FeatureID"]])
    }else{
      feat <- as.character(imp[["FeatureID"]])
    }
    dt <- dt[, c("DataType", "Peptide", "Immunogenicity", "Cluster", feat), with=F]
    gc();gc()
    list("dt"=dt, "feat"=feat, "imp"=imp)
  })
  names(featureImportanceDFList) <- conbinedParamSet
  time.end <- proc.time()
  message("Overall time required = ", format((time.end-time.start)[3], nsmall=2), "[sec]")
  return(featureImportanceDFList)
}
