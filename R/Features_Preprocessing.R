#' Preprocess peptide feature dataframes for machine learning.
#'
#' @param featureDFList A list of feature dataframes generated by \code{Features}.
#' @param metadataDFList A list of metadata dataframes labeled as "Peptide", "Immunogenicity", and "Cluster". No extra metadata is allowed. Feature dataframes are downsized based on the "Peptide" column in this metadata. In other words, peptides not contained in the metadata dataframe are omitted.
#' @param splitDFList A list of feature dataframes generated by \code{Features_SplitDF}.
#' @param preprocessedDFList A list of feature dataframes generated by \code{Features_Preprocess}.
#' @param preprocessedDFList_reference A list of feature dataframes generated by \code{Features_Preprocess} or \code{Features_RFE} for reference.
#' @param coreN The number of cores to be used for parallelization. Set \code{NULL} to skip parallelization.
#' @importFrom dplyr %>%
#' @importFrom dplyr distinct
#' @importFrom dplyr filter
#' @importFrom dplyr mutate
#' @importFrom dplyr left_join
#' @importFrom dplyr select
#' @importFrom data.table as.data.table
#' @importFrom tidyr drop_na
#' @importFrom stringr str_split
#' @importFrom stringr fixed
#' @importFrom rlang set_names
#' @importFrom tibble as_tibble
#' @importFrom DescTools Sort
#' @importFrom bigcov bigcov
#' @importFrom caret createDataPartition
#' @importFrom caret preProcess
#' @importFrom caret rfeControl
#' @importFrom caret rfFuncs
#' @importFrom caret rfe
#' @importFrom caret predictors
#' @importFrom parallel detectCores
#' @importFrom parallel splitIndices
#' @importFrom parallel detectCores
#' @importFrom parallel makeCluster
#' @importFrom parallel clusterEvalQ
#' @importFrom parallel clusterExport
#' @importFrom parallel stopCluster
#' @importFrom doParallel registerDoParallel
#' @importFrom pbapply pbapply
#' @importFrom pbapply pblapply
#' @importFrom foreach foreach
#' @importFrom foreach %do%
#' @export
#' @rdname Features_Preprocessing
#' @name Features_Preprocessing
Features_Preprocess_ByReference <- function(featureDFList, metadataDFList, preprocessedDFList_reference){
  paramDF <- expand.grid(names(metadataDFList), names(featureDFList), stringsAsFactors=F)
  conbinedParamSet <- apply(paramDF, 1, function(v){paste0(v, collapse=".")})
  if(length(conbinedParamSet)!=length(preprocessedDFList_reference)){
    message("length(preprocessedDFList_reference) must be equal to length(featureDFList)*length(metadataDFList) !")
    return(NULL)
  }
  preprocessedDFList <- pbapply::pblapply(1:length(preprocessedDFList_reference), function(i){
    featureSet_reference <- colnames(preprocessedDFList_reference[[i]][["df_train"]])
    pp <- preprocessedDFList_reference[[i]][["pp_train"]]
    f <- featureDFList[[paramDF[[2]][[i]]]]
    m <- featureDFList[[paramDF[[1]][[i]]]]
    d <- dplyr::left_join(m, f, by="Peptide") %>%
      tidyr::drop_na() %>%
      dplyr::mutate(Immunogenicity=factor(Immunogenicity, levels=c("Positive", "Negative")))
    d.pp <- dplyr::select(d, featureSet_reference)
    d.pp <- predict(pp, d.pp)
    return(d.pp)
  })
  names(preprocessedDFList) <- conbinedParamSet
  gc();gc()
  return(preprocessedDFList)
}

#' @export
#' @rdname Features_Preprocessing
#' @name Features_Preprocessing
Features_SplitDF <- function(featureDFList, metadataDFList){
  Features_Split_Single <- function(featureDF, metadataDF, seed=12345){
    # Combine metadata
    df <- dplyr::left_join(metadataDF, featureDF, by="Peptide") %>%
      tidyr::drop_na() %>%
      dplyr::mutate(Immunogenicity=factor(Immunogenicity, levels=c("Positive", "Negative")))

    # Randomly choose one epitope per each cluster [Minor class is prioritized]
    set.seed(seed)
    outcome_table <- table(df$"Immunogenicity")
    if(outcome_table["Positive"]>=outcome_table["Negative"]){
      outcome_minor_major <- c("Negative", "Positive")
    }else{
      outcome_minor_major <- c("Positive", "Negative")
    }
    df <- df %>%
      (function(d){d[sample.int(nrow(d)),]}) %>%
      dplyr::mutate(Immunogenicity=factor(Immunogenicity, levels=outcome_minor_major)) %>%
      dplyr::distinct(Immunogenicity, Cluster, .keep_all=T) %>%
      dplyr::distinct(Cluster, .keep_all=T) %>%
      dplyr::distinct(Peptide, .keep_all=T) %>%
      DescTools::Sort(ord=c("Peptide", "Cluster")) %>%
      dplyr::mutate(Immunogenicity=factor(Immunogenicity, levels=c("Positive", "Negative")))

    # Random data splitting [train:test=7:3]
    set.seed(seed)
    trainID <- caret::createDataPartition(df$"Immunogenicity", p=7/10, list=F)
    trainDF <- data.frame("DataType"=rep("Train", nrow(df)), stringsAsFactors=F)
    trainDF$"DataType"[setdiff(1:nrow(df), trainID)] <- "Test"
    df <- data.table::as.data.table(dplyr::bind_rows(trainDF, df))

    # Output
    rm(list=setdiff(ls(), "df"))
    gc();gc()
    return(df)
  }
  message("Splitting dataframes...")
  paramDF <- expand.grid(names(metadataDFList), names(featureDFList), stringsAsFactors=F)
  conbinedParamSet <- apply(paramDF, 1, function(v){paste0(v, collapse=".")})
  splitDFList <- pbapply::pbapply(
    paramDF, 1,
    function(v){
      s <- as.numeric(as.character(rev(unlist(stringr::str_split(v[[2]], stringr::fixed("."))))[1]))
      Features_Split_Single(featureDFList[[v[2]]], metadataDFList[[v[1]]], s)
    }
  )
  names(splitDFList) <- conbinedParamSet
  gc();gc()
  return(splitDFList)
}

#' @export
#' @rdname Features_Preprocessing
#' @name Features_Preprocessing
Features_Preprocess <- function(splitDFList){
  Features_Preprocess_Single <- function(df){
    # Feature elimination by variances and correlations
    dt <- data.table::as.data.table(df)
    dt <- dt[DataType=="Train", ,]
    dt <- dt[, -c("DataType", "Peptide", "Immunogenicity", "Cluster"), with=F]
    message("Variance-based feature elimination.")
    removedFeatureSet <- caret::nearZeroVar(dt, saveMetrics=F, names=T, foreach=T, allowParallel=T)
    dt <- dt[, -removedFeatureSet, with=F]
    message(length(removedFeatureSet), " features were removed based on their variances.")
    gc();gc()
    message("Correlation-based feature elimination.")
    corMat <- bigcov::bigcov(dt, center=T, scale=T, num_splits=3, verbose=2)
    removedFeatureSet <- caret::findCorrelation(corMat, cutoff=0.6, verbose=F, names=T)
    dt <- dt[, -removedFeatureSet, with=F]
    message(length(removedFeatureSet), " features were removed based on their correlations.")
    gc();gc()

    # Rescaling
    featureSet <- colnames(dt)
    dummyFeatureSet <- grep("Peptide_", colnames(dt), value=T)
    dt <- dt[, -dummyFeatureSet, with=F]
    pp_train <- caret::preProcess(dt, method=c("center", "scale"), verbose=T)
    dt <- data.table::as.data.table(df)
    dt <- dt[, c("DataType", "Peptide", "Immunogenicity", "Cluster", featureSet), with=F]
    dt <- data.table::as.data.table(predict(pp_train, dt))

    # Output
    rm(list=setdiff(ls(), c("dt", "pp_train")))
    gc();gc()
    list("dt"=dt, "pp_train"=pp_train)
  }
  message("Preprocessing...")
  time.start <- proc.time()
  conbinedParamSet <- names(splitDFList)
  preprocessedDTList <- foreach::foreach(i=1:length(conbinedParamSet)) %do% {
    cat(i, "/", length(conbinedParamSet), ":", conbinedParamSet[i], sep="")
    Features_Preprocess_Single(splitDFList[[i]])
  }
  names(preprocessedDTList) <- conbinedParamSet
  gc();gc()
  time.end <- proc.time()
  message("Overall time required = ", format((time.end-time.start)[3], nsmall=2), "[sec]")
  return(preprocessedDTList)
}

#' @export
#' @rdname Features_Preprocessing
#' @name Features_Preprocessing
Features_RFE <- function(preprocessedDFList, coreN=parallel::detectCores()){
  caretSeeds <- function(seed, number){
    set.seed(seed)
    seeds <- vector(mode="list", length=number+1)
    for(i in 1:number) seeds[[i]] <- sample.int(10000, 2)
    seeds[[number+1]] <- sample.int(10000, 1)
    return(seeds)
  }
  caretSeedsList <- foreach::foreach(param=conbinedParamSet) %do% {
    s <- as.numeric(as.character(rev(unlist(stringr::str_split(param, stringr::fixed("."))))[1]))
    caretSeeds(s, number=10)
  }
  Features_RFE_Single <- function(df, pp_train, seeds, coreN){
    # Recursive feature elimination
    dt <- data.table::as.data.table(df)
    dt <- dt[DataType=="Train", ,]
    outcomes <- dt$"Immunogenicity"
    dt <- dt[, -c("DataType", "Peptide", "Immunogenicity", "Cluster"), with=F]
    rfeCtrl <- caret::rfeControl(
      functions=caret::rfFuncs, method="cv", number=10,
      verbose=T, seeds=seeds, allowParallel=T
    )
    if(!is.null(coreN)){
      cl <- parallel::makeCluster(coreN, type='SOCK')
      doParallel::registerDoParallel(cl)
      rfeRes <- caret::rfe(
        dt, outcomes,
        sizes=100, metric="Kappa", rfeControl=rfeCtrl
      )
      parallel::stopCluster(cl)
    }else{
      rfeRes <- caret::rfe(
        dt, outcomes,
        sizes=100, metric="Kappa", rfeControl=rfeCtrl
      )
    }
    rfeFeatureSet <- caret::predictors(rfeRes)
    dt <- data.table::as.data.table(df)
    dt <- dt[, c("DataType", "Peptide", "Immunogenicity", "Cluster", rfeFeatureSet), with=F]

    # Output
    rm(list=setdiff(ls(), c("dt", "pp_train", "rfeRes")))
    gc();gc()
    list("dt"=dt, "pp_train"=pp_train, "rfeRes"=rfeRes)
  }
  message("Recursive feature elimination...")
  time.start <- proc.time()
  conbinedParamSet <- names(preprocessedDFList)
  preprocessedDTList <- foreach::foreach(i=1:length(conbinedParamSet)) %do% {
    cat(i, "/", length(conbinedParamSet), ":", conbinedParamSet[i], sep="")
    Features_RFE_Single(
      preprocessedDFList[[i]][["dt"]], preprocessedDFList[[i]][["pp_train"]],
      seeds=caretSeedsList[[i]], coreN=coreN
    )
  }
  names(preprocessedDTList) <- conbinedParamSet
  gc();gc()
  time.end <- proc.time()
  message("Overall time required = ", format((time.end-time.start)[3], nsmall=2), "[sec]")
  return(preprocessedDTList)
}
